{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd47d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from elasticsearch.helpers import bulk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1426a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN='cs-AI'\n",
    "GOOGLE_CLOUD_PROJECT='arxiv-trends'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbde92",
   "metadata": {},
   "source": [
    "Get environment variables with dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae38d36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72888158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabateri/anaconda3/envs/llm-project/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "client = bigquery.Client(project=GOOGLE_CLOUD_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b8f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bq_data(domain='cs-AI'):\n",
    "    domain_cleaned = domain.replace(\"-\", \"_\")\n",
    "    domain_cleaned = domain_cleaned.replace(\".\", \"_\")\n",
    "    sql_query = f\"\"\"\n",
    "    SELECT id, title, summary, author\n",
    "    FROM `arxiv-trends.arxiv_papers.arxiv_papers_2000_2025_{domain_cleaned}`\n",
    "    WHERE summary IS NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "    query_job = client.query(sql_query)\n",
    "    results = query_job.result().to_dataframe()\n",
    "    return results\n",
    "\n",
    "raw_arxiv_df = get_bq_data(domain=DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0726f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1405.3637v2</td>\n",
       "      <td>Vicious Circle Principle and Logic Programs wi...</td>\n",
       "      <td>The paper presents a knowledge representation ...</td>\n",
       "      <td>[Michael Gelfond, Yuanlin Zhang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/1608.08262v1</td>\n",
       "      <td>Vicious Circle Principle and Formation of Sets...</td>\n",
       "      <td>The paper continues the investigation of Poinc...</td>\n",
       "      <td>[Michael Gelfond, Yuanlin Zhang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/1808.07050v1</td>\n",
       "      <td>Vicious Circle Principle and Logic Programs wi...</td>\n",
       "      <td>The paper presents a knowledge representation ...</td>\n",
       "      <td>[Michael Gelfond, Yuanlin Zhang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/2102.04323v2</td>\n",
       "      <td>Discovering a set of policies for the worst ca...</td>\n",
       "      <td>We study the problem of how to construct a set...</td>\n",
       "      <td>[Tom Zahavy, Andre Barreto, Daniel J Mankowitz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/2309.13426v2</td>\n",
       "      <td>A Chat About Boring Problems: Studying GPT-bas...</td>\n",
       "      <td>Text normalization - the conversion of text fr...</td>\n",
       "      <td>[Yang Zhang, Travis M. Bartley, Mariana Grater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109198</th>\n",
       "      <td>http://arxiv.org/abs/2406.11326v1</td>\n",
       "      <td>GitHub Copilot: the perfect Code compLeeter?</td>\n",
       "      <td>This paper aims to evaluate GitHub Copilot's g...</td>\n",
       "      <td>[Ilja Siroš, Dave Singelée, Bart Preneel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109199</th>\n",
       "      <td>http://arxiv.org/abs/physics/0005062v1</td>\n",
       "      <td>Applying MDL to Learning Best Model Granularity</td>\n",
       "      <td>The Minimum Description Length (MDL) principle...</td>\n",
       "      <td>[Qiong Gao, Ming Li, Paul Vitanyi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109200</th>\n",
       "      <td>http://arxiv.org/abs/2202.07290v1</td>\n",
       "      <td>Don't stop the training: continuously-updating...</td>\n",
       "      <td>Over the last decade, numerous studies have sh...</td>\n",
       "      <td>[Pierre Orhan, Yves Boubenec, Jean-Rémi King]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109201</th>\n",
       "      <td>http://arxiv.org/abs/1911.00572v1</td>\n",
       "      <td>Probabilistic Formulation of the Take The Best...</td>\n",
       "      <td>The framework of cognitively bounded rationali...</td>\n",
       "      <td>[Tomi Peltola, Jussi Jokinen, Samuel Kaski]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109202</th>\n",
       "      <td>http://arxiv.org/abs/2402.09723v3</td>\n",
       "      <td>Efficient Prompt Optimization Through the Lens...</td>\n",
       "      <td>The remarkable instruction-following capabilit...</td>\n",
       "      <td>[Chengshuai Shi, Kun Yang, Zihan Chen, Jundong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109203 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            id  \\\n",
       "0             http://arxiv.org/abs/1405.3637v2   \n",
       "1            http://arxiv.org/abs/1608.08262v1   \n",
       "2            http://arxiv.org/abs/1808.07050v1   \n",
       "3            http://arxiv.org/abs/2102.04323v2   \n",
       "4            http://arxiv.org/abs/2309.13426v2   \n",
       "...                                        ...   \n",
       "109198       http://arxiv.org/abs/2406.11326v1   \n",
       "109199  http://arxiv.org/abs/physics/0005062v1   \n",
       "109200       http://arxiv.org/abs/2202.07290v1   \n",
       "109201       http://arxiv.org/abs/1911.00572v1   \n",
       "109202       http://arxiv.org/abs/2402.09723v3   \n",
       "\n",
       "                                                    title  \\\n",
       "0       Vicious Circle Principle and Logic Programs wi...   \n",
       "1       Vicious Circle Principle and Formation of Sets...   \n",
       "2       Vicious Circle Principle and Logic Programs wi...   \n",
       "3       Discovering a set of policies for the worst ca...   \n",
       "4       A Chat About Boring Problems: Studying GPT-bas...   \n",
       "...                                                   ...   \n",
       "109198       GitHub Copilot: the perfect Code compLeeter?   \n",
       "109199    Applying MDL to Learning Best Model Granularity   \n",
       "109200  Don't stop the training: continuously-updating...   \n",
       "109201  Probabilistic Formulation of the Take The Best...   \n",
       "109202  Efficient Prompt Optimization Through the Lens...   \n",
       "\n",
       "                                                  summary  \\\n",
       "0       The paper presents a knowledge representation ...   \n",
       "1       The paper continues the investigation of Poinc...   \n",
       "2       The paper presents a knowledge representation ...   \n",
       "3       We study the problem of how to construct a set...   \n",
       "4       Text normalization - the conversion of text fr...   \n",
       "...                                                   ...   \n",
       "109198  This paper aims to evaluate GitHub Copilot's g...   \n",
       "109199  The Minimum Description Length (MDL) principle...   \n",
       "109200  Over the last decade, numerous studies have sh...   \n",
       "109201  The framework of cognitively bounded rationali...   \n",
       "109202  The remarkable instruction-following capabilit...   \n",
       "\n",
       "                                                   author  \n",
       "0                        [Michael Gelfond, Yuanlin Zhang]  \n",
       "1                        [Michael Gelfond, Yuanlin Zhang]  \n",
       "2                        [Michael Gelfond, Yuanlin Zhang]  \n",
       "3       [Tom Zahavy, Andre Barreto, Daniel J Mankowitz...  \n",
       "4       [Yang Zhang, Travis M. Bartley, Mariana Grater...  \n",
       "...                                                   ...  \n",
       "109198          [Ilja Siroš, Dave Singelée, Bart Preneel]  \n",
       "109199                 [Qiong Gao, Ming Li, Paul Vitanyi]  \n",
       "109200      [Pierre Orhan, Yves Boubenec, Jean-Rémi King]  \n",
       "109201        [Tomi Peltola, Jussi Jokinen, Samuel Kaski]  \n",
       "109202  [Chengshuai Shi, Kun Yang, Zihan Chen, Jundong...  \n",
       "\n",
       "[109203 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_arxiv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf9abed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>http://arxiv.org/abs/2412.13337v1</td>\n",
       "      <td>Unveiling the Secret Recipe: A Guide For Super...</td>\n",
       "      <td>The rise of large language models (LLMs) has c...</td>\n",
       "      <td>[Aldo Pareja, Nikhil Shivakumar Nayak, Hao Wan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "2967  http://arxiv.org/abs/2412.13337v1   \n",
       "\n",
       "                                                  title  \\\n",
       "2967  Unveiling the Secret Recipe: A Guide For Super...   \n",
       "\n",
       "                                                summary  \\\n",
       "2967  The rise of large language models (LLMs) has c...   \n",
       "\n",
       "                                                 author  \n",
       "2967  [Aldo Pareja, Nikhil Shivakumar Nayak, Hao Wan...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_arxiv_df[raw_arxiv_df['id'] == 'http://arxiv.org/abs/2412.13337v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bcd3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicates: 109203 -> 109203 rows\n"
     ]
    }
   ],
   "source": [
    "# Add this before bulk indexing\n",
    "arxiv_df = raw_arxiv_df.drop_duplicates(subset=['id'])\n",
    "print(f\"Removed duplicates: {len(raw_arxiv_df)} -> {len(arxiv_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a09608",
   "metadata": {},
   "source": [
    "### Elastic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407da148",
   "metadata": {},
   "source": [
    "To use elastic search\n",
    "``` \n",
    "docker run --name es01 --net elastic -p 9200:9200 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.13.4 \n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63667cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Connect to your ES instance\n",
    "es = Elasticsearch(\n",
    "    \"http://localhost:9200\",  # Or your cloud instance\n",
    "    #basic_auth=(\"user\", \"password\")  # Only if authentication is enabled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4bdf444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(es.ping())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c778ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"arxiv-papers\"\n",
    "\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"summary\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"author\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            #\"published\": {\"type\": \"date\"},\n",
    "            #\"categories\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1e906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_docs(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row[\"id\"],\n",
    "            \"_source\": {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"summary\": row[\"summary\"],\n",
    "                \"author\": row[\"author\"],\n",
    "                # \"published\": row[\"published\"].isoformat() if row[\"published\"] else None,\n",
    "                # \"categories\": row[\"categories\"]\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "745963cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(query, top_k=10):\n",
    "    # Text-based search\n",
    "    text_query = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"title^2\", \"summary\", \"author\"],\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        },\n",
    "        \"size\": top_k\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=text_query)\n",
    "    \n",
    "    results = []\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        results.append({\n",
    "            \"score\": hit[\"_score\"],\n",
    "            \"id\": hit[\"_source\"][\"id\"],\n",
    "            \"title\": hit[\"_source\"][\"title\"],\n",
    "            \"summary\": hit[\"_source\"][\"summary\"],\n",
    "            \"author\": hit[\"_source\"][\"author\"]\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca5c0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "llm_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91be2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, relevant_papers, model):\n",
    "    \n",
    "    # Build context from summaries\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"id: {paper['id']}\\nPaper: {paper['title']}\\nSummary: {paper['summary']}\"\n",
    "        for paper in relevant_papers\n",
    "    ])\n",
    "    \n",
    "    # Create prompt for LLM\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following research paper summaries, answer the question: {question}\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Send to your LLM of choice (OpenAI, etc.)\n",
    "    llm_response = llm_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "    return {\n",
    "        \"llm_answer\": llm_response,\n",
    "        \"sources\": relevant_papers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, top_k, model):\n",
    "    # bulk index all documents\n",
    "    bulk(es, generate_docs(arxiv_df))\n",
    "\n",
    "    # search top N papers using elastic search\n",
    "    relevant_papers = search_papers(query, top_k=top_k)\n",
    "\n",
    "    # generate llm answer based on the relevant papers\n",
    "    answer = answer_question(query, relevant_papers=relevant_papers, model=model)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06f82236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the most recent approaches to getting strong fine‐tuning results when you only have a few thousand (or fewer) examples:\n",
      "\n",
      "1. Supervised “secret-recipe” tuning for 3–7B‐parameter models (arXiv:2412.13337v1)  \n",
      "   • Instruction-tune small open‐source LLMs with standard multi‐task/instruction datasets (e.g. stacked rather than phased training)  \n",
      "   • Use unusually large batch sizes coupled with very low peak learning rates  \n",
      "   • Monitor early training signals (gradient norms, loss curves) to early-stop poor runs and save compute  \n",
      "   • Simplify warm-up schedules and learning-rate decay without hurting final accuracy  \n",
      "   • Stacked (all tasks at once) training works just as well as multi-phase curricula and is more sample-efficient  \n",
      "\n",
      "2. Contrastive fine-tuning of embeddings with expert-augmented soft labels (arXiv:2408.11868v1)  \n",
      "   • When you care about retrieval/semantic-similarity rather than full autoregressive outputs, use contrastive objectives on your small dataset  \n",
      "   • Augment each example with a “soft” similarity score from one or more expert annotators or models  \n",
      "   • Fine-tune a pre-trained embedding model so that examples with higher expert scores are pulled closer in vector space  \n",
      "   • Retains general embedding capabilities while measurably boosting performance on your custom retrieval or STS tasks  \n",
      "\n",
      "3. Privacy-and-proprietary-model friendly tuning (ObfuscaTune, arXiv:2407.02960v2)  \n",
      "   • If you must fine-tune a closed-source LLM on private data, run most of the model offsite in an encrypted/obfuscated form  \n",
      "   • Place only a small fraction of the parameters (∼5%) inside a Trusted Execution Environment (TEE)  \n",
      "   • Use low‐condition‐number random matrices to “scramble” activations/gradients so that neither the host nor the cloud can recover your raw data or the model weights  \n",
      "   • Achieves nearly the same utility as standard fine-tuning while preserving confidentiality of both model and data  \n",
      "\n",
      "Taken together, these papers show that even on very small task-specific corpora you can get good results by:  \n",
      " 1) carefully choosing batch size & learning‐rate regimes,  \n",
      " 2) exploiting early-training diagnostics for compute savings,  \n",
      " 3) using contrastive/soft-label losses for embedding tasks, and  \n",
      " 4)—in regulated or proprietary scenarios—leveraging obfuscation + confidential computing to fine-tune without data/model leakage.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest methods for fine-tuning LLMs on small datasets?\"\n",
    "answer = rag(query,top_k=5,model=\"o4-mini\")\n",
    "print(answer['llm_answer'].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04807fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
